---
title: "AMPH 2025: Forecasting with Time Series Models"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
editor_options:
  chunk_output_type: console
---

# Set parameters

```{r set-params}
state_name <- "Maryland"
geo_values <- "md"
forecast_disease <- "rsv"
nowcast_date = "2025-07-02"
eval_date = "2025-09-21"
```

# Install packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(AMPHForecastSuite)
# needs: install.packages("lme4")
#install.packages("epinowcast", repos = "https://epinowcast.r-universe.dev")
# install_github("epinowcast/baselinenowcast")
# or pak::pak(file.path("epinowcast", "baselinenowcast"))
library(baselinenowcast)
library(epinowcast)


# Run `remotes::install_github("ACCIDDA/AMPH_Forecast_Suite")` if the package is not installed.

library(tidyverse)
library(ggplot2)
library(epidatr)
```


# Save and check API key

1. Go to https://api.delphi.cmu.edu/epidata/admin/registration_form and register for a psuedo-anonymous account.

2. Run the command below to save your API key in your `.Renviron` file. As it says in the prompt, add a line `DELPHI_EPIDATA_KEY=yourkeyhere` to your `.Renviron` file. Save and close the file, then restart R or RStudio. After restarting, run the command `epidatr::get_api_key()` to check that your API key is saved.

```{r epidatr_api, eval=FALSE}

# Follow instructions about opening `.Renviron` file
#epidatr::save_api_key()

# Check that the API key is saved
epidatr::get_api_key()

```

# Pull directly with epidatr

```{r}

  # Map disease names to NHSN signal names
  # Based on epidatr NHSN signals for respiratory diseases
  signal_map <- list(
    "influenza" = "confirmed_admissions_flu_ew",
    "covid" = "confirmed_admissions_covid_ew",
    "rsv" = "confirmed_admissions_rsv_ew"
  )
  signal <- signal_map[[forecast_disease]]

  # Call epidatr to get the data
  epidata <- epidatr::pub_covidcast(
    source = "nhsn",
    signals = signal,
    geo_type = "state",
    time_type = "week",
    geo_values = tolower(geo_values),
    issues = "*"
  )
  
  epidata_cleaned <- epidata %>% 
    select(location = geo_value, reference_date = time_value, report_date = issue , confirm=value)

  target_data <- epidata_cleaned |>
    enw_filter_report_dates(latest_date = eval_date) |>
    enw_filter_reference_dates(latest_date = nowcast_date)
  epidata$issue %>% unique()
```

The epinowcast function enw_latest_data() will be used to filter observations to the latest available reported total counts for each reference date. The epinowcast function enw_filter_report_dates() will be used to create a truncated dataset for generating a retrospective nowcast, using the data that would have been available as of the nowcast date.


```{r}
latest_data <- enw_latest_data(target_data)

observed_data <- enw_filter_report_dates( target_data, latest_date = nowcast_date)

obs_data_by_reference_date <- enw_latest_data(observed_data)

head(observed_data)

# filder so observed_data and latest_data end on the same day.
latest_data <- latest_data %>% enw_filter_reference_dates(latest_date = max(observed_data$reference_date))

```

The red line shows the total number of confirmed admissions on each reference date, across all delays, using the data available at the nowcast date, whereas the blackline show the final value of the data.
``` {r}
plot_data <- ggplot() +
  geom_line(
    data = obs_data_by_reference_date,
    aes(x = reference_date, y = confirm), color = "darkred"
  ) +
  geom_line(
    data = latest_data,
    aes(x = reference_date, y = confirm), color = "black"
  ) +
  theme_bw() +
  xlab("Reference date") +
  ylab(signal) +
  #scale_y_continuous(trans = "log10") +
  xlim(as.Date("2025-05-01"), as.Date(nowcast_date)) 
  ggtitle("Comparing real-time and later observed cases")
plot_data
```

## Preprocessing
``` {r}
# Empirical data outside this delay window will not be used for training
max_delay <- 3 # weeks

n_training_volume <- 30*7 # days
```

Next we will use the epinowcast function, enw_filter_reference_dates() to filter to only include n_training_volume days of historical data, and the epinowcast function enw_latest_data() will be used to filter for the latest available reported total counts for each reference date. Finally to obtain the data we want to evaluate the forecasts against, we will use enw_filter_reference_dates() applied to the target_data, to filter it for only the n_training_volume days of historical data.

``` {r}
training_data <- enw_filter_reference_dates(observed_data, include_days = n_training_volume)

latest_training_data <- enw_latest_data(training_data)

eval_data <- enw_filter_reference_dates(latest_data, include_days = n_training_volume-1)

```
  
## reporting triangle
``` {r}
pobs <- enw_preprocess_data(
  obs = training_data,
  max_delay = max_delay+2,
  timestep="week",
  set_negatives_to_zero = TRUE
)
reporting_triangle_df <- select(
  pobs$new_confirm[[1]],
  reference_date,
  delay,
  new_confirm
)

```

``` {r}
reporting_triangle <- reporting_triangle_df |>
  pivot_wider(names_from = delay, values_from = new_confirm) |>
  select(-reference_date) |>
  as.matrix()

reporting_triangle[is.na(reporting_triangle)] <- 0




#### code to plot:
triangle_df <- as.data.frame(reporting_triangle) |>
  mutate(time = row_number()) |>
  pivot_longer(!time,
    values_to = "count",
    names_prefix = "V",
    names_to = "delay"
  ) |>
  mutate(delay = as.numeric(delay))

plot_triangle <- ggplot(
  triangle_df,
  aes(x = delay, y = time, fill = count)
) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  labs(title = "Reporting triangle", x = "Delay", y = "Time") +
  theme_bw() +
  scale_y_reverse()

plot_triangle
```
Here, the grey indicates matrix elements that are NA, which we would expect to be the case in the bottom right portion of the reporting triangle where the counts have yet to be observed.


## Estimate delay

``` {r}

# most recent 50% of the reference times for delay estimation
n_history_delay <- as.integer(0.5 * n_training_volume) # days

delay_pmf <- estimate_delay(
  reporting_triangle = reporting_triangle,
  max_delay = max_delay,
  n = n_history_delay/7
)

```


``` {r}
delay_df <- data.frame(
  delay = 0:(length(delay_pmf) - 1),
  pmf = delay_pmf
)

delay_cdf_plot <- ggplot(delay_df) +
  geom_line(aes(x = delay, y = cumsum(pmf))) +
  xlab("Delay") +
  ylab("Cumulative proportion reported") +
  ggtitle("Empirical point estimate of cumulative proportion reported by delay") + # nolint
  theme_bw()

delay_pmf_plot <- ggplot(delay_df) +
  geom_line(aes(x = delay, y = pmf)) +
  xlab("Delay") +
  ylab("Proportion reported") +
  ggtitle("Empirical point estimate of proportion reported by delay") +
  theme_bw()


```

``` {r}
delay_cdf_plot
delay_pmf_plot
```
## Apply the delay to generate a point nowcast


``` {r}
point_nowcast_matrix <- apply_delay(
  reporting_triangle = reporting_triangle,
  delay_pmf = delay_pmf
)

```


``` {r}
point_nowcast_df <- eval_data |>
  mutate(nowcast = rowSums(point_nowcast_matrix))

prep_latest_data <- latest_training_data |>
  mutate(type = "Real-time data") |>
  select(type, reference_date, count = confirm)
# Combine data into a single dataframe for plotting
plot_data <- point_nowcast_df |>
  pivot_longer(
    cols = c(confirm, nowcast),
    names_to = "type",
    values_to = "count"
  ) |>
  mutate(type = case_when(
    type == "confirm" ~ "Final observed data",
    type == "nowcast" ~ "Point nowcast",
    TRUE ~ type
  )) |>
  bind_rows(prep_latest_data)

# Create plot with data type as a variable
plot_pt_nowcast <- ggplot(plot_data, aes(
  x = reference_date,
  y = count,
  color = type
)) +
  geom_line() +
  scale_color_manual(values = c(
    "Real-time data" = "darkred",
    "Final observed data" = "black",
    "Point nowcast" = "darkblue"
  )) +
  theme_bw() +
  xlab("Reference date") +
  ylab("Confirmed admissions") +
  scale_y_continuous(trans = "log10") +
  ggtitle("Comparing real-time, nowcasted, and later observed cases") +
  theme(legend.position = "bottom") +
  labs(color = "Type")
```


``` {r}
plot_pt_nowcast
```

``` {r}
# For uncertainty estimation, we will generate retrospective nowcast datasets with the most recent 50% of the reference times.
n_retrospective_nowcasts <- as.integer(0.5 * n_training_volume) # days
```