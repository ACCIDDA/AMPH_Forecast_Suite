---
title: "3. Forecasting with Time Series Models"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
editor_options:
  chunk_output_type: console
---

# Setup

## Set parameters

```{r set-params}
state_name <- "Maryland"
geo_ids <- "md"
forecast_date <- as.Date("2024-12-01")
forecast_disease <- "influenza"
target <- "wk inc flu hosp"
forecast_horizon_wks <- 0:3
```

## Load packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(AMPHForecastSuite)
library(tidyverse)
library(forecast)
library(jsonlite)
library(epidatr)
library(epipredict)
library(epiprocess)
```

## Load target (observed) data

We already pulled and saved the data we need in `Collect Empirical Data`. See `vignettes/collect_empirical_data.Rmd` for details.

```{r read-target}

# Load data saved from a specific forecast date: 
target_data_path <- file.path("target-data", paste0("target-hospital-admissions-", forecast_date, ".csv"))
target_data <- readr::read_csv(file = target_data_path) %>% mutate(location = as.character(location))

# get location id to add to forecast output
location_dat <- target_data %>%
  dplyr::select(location, abbreviation, location_name) %>%
  distinct() 
location <- as.character(location_dat$location)

```

## Define Reference date

The `reference_date` is the Saturday for the week of the forecast date. This is the date that will be used in the forecast submission file.

```{r define-ref-date}
reference_date <- get_reference_date(forecast_date)
```

```{r echo=FALSE}
message("Reference date: ", reference_date)
message("Forecast date: ", forecast_date)
```



# Models


## SARIMA (`forecast` package)

Here we use the `auto.arima` function from the `forecast` package to fit a seasonal ARIMA model to the data.

### Set the name
```{r}
model_name <- "AMPH-sarima"
```

### Run the model
```{r sarima-model}
fc_sarima <- forecast::auto.arima(y = target_data$observation, 
                                  seasonal = T, 
                                  lambda = "auto") %>%
  forecast::forecast(h = length(forecast_horizon_wks),
                     level = c(.1, .2, .3, .4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98))

```

### Check that the model output is in the correct format.
We use the `hubValidations` package to check against the `tasks.json` file we create in `Getting Started`.

```{r}
# Future functionality. Not yet developed.
```

### Save in hubVerse Format

```{r save-sarima-output}

# Transform to hubVerse format
data_fc_sarima <- trans_forecastpkg_hv(fc_output = fc_sarima,
                                       model_name = model_name,
                                       target = target,
                                       reference_date = reference_date,
                                       horizon_time_steps = forecast_horizon_wks,
                                       geo_ids = location)


## Save data file
#' -- this will have validation build in for fluid workflow eventually.
save_model_output(model_name = model_name,
                  fc_output = data_fc_sarima,
                  reference_date)

```



## Neural network model (`forecast` package)

Here we use the `nnetar` function from the `forecast` package to fit a neural network model to the data.

### Set the name
```{r}
model_name <- "AMPH-neuralnetwork"
```

### Run the model
```{r neuralnet-model}

fc_nnet <- forecast::nnetar(target_data$observation, 
                            lambda = "auto") %>%
  forecast(PI = TRUE,
           h = length(forecast_horizon_wks),
           level = c(.1, .2, .3, .4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.98))

```

### Save in hubVerse Format

```{r save-nnet-output}

# Transform to hubVerse format
data_fc_nnet <- trans_forecastpkg_hv(fc_output = fc_nnet,
                                     model_name = model_name,
                                     target = target,
                                     reference_date = reference_date,
                                     horizon_time_steps = forecast_horizon_wks,
                                     geo_ids = location)

## Save data file
#' -- this will have validation build in for fluid workflow eventually.
save_model_output(model_name = model_name,
                  fc_output = data_fc_nnet,
                  reference_date)

unique(data_fc_nnet$output_type_id)
```


## Autoregressive Forecaster (`epipredict` package)    

Here we use the `epipredict` package to fit an autoregressive model to the data. We specify lags of 0, 7, and 14 days (i.e., current week, previous week, and two weeks ago) and forecast horizons of 7, 14, 21, and 28 days ahead (i.e., 1 to 4 weeks ahead).

### Set the name
```{r}
model_name <- "AMPH-epipredict-arx"
```

### Run the model
```{r epipredict-arx-model}
# Set up data for epipredict
target_data_arx <- target_data %>%
  rename(geo_value = location,
         time_value = target_end_date,
         value = observation) %>%
  tsibble::as_tsibble(index = time_value, key = c(geo_value)) %>%
  arrange(geo_value, time_value) %>%
  epiprocess::as_epi_df()

# Run model
arx_forecast <- lapply(
  seq(7, 28, 7),
  function(days_ahead) {
    epipredict::arx_forecaster(
      epi_data = target_data_arx, 
      outcome = "value",
      trainer = linear_reg(),
      predictors = "value",
      args_list = arx_args_list(
        lags = list(c(0, 7, 14)),
        ahead = days_ahead,
        quantile_levels = c(0.01, 0.025, seq(.05, .95, .05), 0.975, 0.99),
        nonneg = TRUE
      )
    )
  }
)
```


```{r fig.alt="ARX model fit and forecast", fig.cap="ARX model fit and forecast"}
# pull out the workflow and the predictions to be able to effectively use autoplot
arx_forecaster_workflow <- arx_forecast[[1]]$epi_workflow
arx_forecaster_results <- arx_forecast %>%
  purrr::map(~ `$`(., "predictions")) %>%
  list_rbind() %>%
  mutate(horizon = forecast_horizon_wks,
         location_id = state_name,
         model = model_name,
         target = target)
autoplot(
  object = arx_forecaster_workflow,
  predictions = arx_forecaster_results,
  observed_response = target_data_arx %>%
    filter(geo_value %in% geo_ids, time_value > (lubridate::as_date(forecast_date) - 4*30))) +
  geom_vline(aes(xintercept = forecast_date))

```

### Save in hubVerse Format

```{r save-arx-output}

# Transform to hubVerse format
data_fc_arx_epipred <- trans_epipredarx_hv(fc_output = arx_forecast,
                                           model_name = model_name,
                                           target = target,
                                           reference_date = reference_date,
                                           horizon_time_steps = forecast_horizon_wks)

## Save data file
#' -- this will have validation build in for fluid workflow eventually.
save_model_output(model_name = model_name,
                  fc_output = data_fc_arx_epipred,
                  reference_date)

```



## Climatological Forecaster (`epipredict` package)    

Here we use the `epipredict` package to fit a climatological model to the data. We specify a forecast horizon of 7, 14, 21, and 28 days ahead (i.e., 1 to 4 weeks ahead).

### Set the name
```{r}
model_name <- "AMPH-epipredict-climate"
```

### Run the model
```{r epipredict-climate-model}
# Set up data for epipredict
target_data_clim <- target_data %>%
  rename(geo_value = location,
         time_value = target_end_date,
         value = observation) %>%
  tsibble::as_tsibble(index = time_value, key = c(geo_value)) %>%
  arrange(geo_value, time_value) %>%
  epiprocess::as_epi_df()

# Run the model
climate_forecast <- epipredict::climatological_forecaster(
  target_data_clim,
  outcome = "value",
  args_list = climate_args_list(
    forecast_horizon = forecast_horizon_wks,
    time_type = "week",
    quantile_levels = c(0.01, 0.025, seq(.05, .95, .05), 0.975, 0.99),
    center_method = "mean",
    quantile_by_key = "geo_value",
    forecast_date = reference_date,
    nonneg = TRUE
  )
)
climate_forecast_workflow <- climate_forecast$epi_workflow
climate_forecast_results <- climate_forecast$predictions %>%
  mutate(horizon = forecast_horizon_wks,
         location_id = state_name,
         model = model_name,
         target = target)
```


```{r fig.alt="Climate model fit and forecast", fig.cap="Climate model fit and forecast"}
autoplot(
  object = climate_forecast_workflow,
  predictions = climate_forecast_results,
  observed_response = target_data_clim %>%
    filter(geo_value %in% geo_ids, time_value > (lubridate::as_date(forecast_date) - 4*30))) +
  geom_vline(aes(xintercept = forecast_date))
```

### Save in hubVerse Format

```{r save-clim-output}

# Transform to hubVerse format
hub_forecast <- trans_epipredclim_hv(fc_output = climate_forecast,
                                     model_name = model_name,
                                     target = target,
                                     reference_date = reference_date,
                                     horizon_time_steps = forecast_horizon_wks)

## Save data file
#' -- this will have validation build in for fluid workflow eventually.
save_model_output(model_name = model_name,
                  fc_output = data_fc_arx_epipred,
                  reference_date)
```
